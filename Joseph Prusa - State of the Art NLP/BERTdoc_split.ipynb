{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForNextSentencePrediction \n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_follows(sentence1, sentence2):\n",
    "    # predicts if sentence2 makes sense in the context of following sentence 1\n",
    "    text = '[CLS] '+sentence1+' [SEP] '+sentence2+' [SEP]'\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    \n",
    "    segments_ids = [0 for i in tokenized_text]\n",
    "    sent1_len = len(tokenizer.tokenize(sentence1))+2\n",
    "    segments_ids[sent1_len:] = [1 for i in segments_ids[sent1_len:]]\n",
    "        \n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    next_sentence_label = torch.tensor([[0]])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(tokens_tensor, segments_tensors, next_sentence_label=next_sentence_label)\n",
    "\n",
    "    return(predictions.item())\n",
    "    \n",
    "def doc_split(text, thresh):\n",
    "    # returns list of doc splits\n",
    "    # splits are generated when a sentence does not seem to follow the previous one. \n",
    "    # text, document text\n",
    "    # thresh, controls when to split by comparing against loss for the model's prediction against the assumption the sentences are concurrent.\n",
    "    # small values of thresh mean sentences must be more similar to not be split.\n",
    "    doc = nlp(text)\n",
    "    docs = []\n",
    "    sentences = [str(sent) for sent in doc.sents]\n",
    "    current = sentences[0]\n",
    "    if len(sentences) > 1:\n",
    "        for i in range(1,len(sentences)):\n",
    "            \n",
    "            loss = predict_follows(sentences[i-1], sentences[i])\n",
    "            if loss > thresh:\n",
    "                docs.append(current)\n",
    "                current = sentences[i]   \n",
    "            else:\n",
    "                current += ' '+sentences[i]\n",
    "        if current not in docs:\n",
    "            docs.append(current)\n",
    "    else:\n",
    "        docs.append(str(list(doc.sents)[0]))\n",
    "\n",
    "    return(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of these sentences is not like the other. This sentence could logically follow the first as it pretains to the task at hand. A final sentence similar to the first two in that it discuesses being a sentence in a sequnece.\n"
     ]
    }
   ],
   "source": [
    "sentences = \"\"\"\\\n",
    "One of these sentences is not like the other. \\\n",
    "This sentence could logically follow the first as it pretains to the task at hand. \\\n",
    "A final sentence similar to the first two in that it discuesses being a sentence in a sequnece. \\\n",
    "\"\"\"\n",
    "\n",
    "for sentence_block in doc_split(sentences, 0.00001): # try playing with the value, notice it splits the document into 3 peices due to the offending sentence.\n",
    "    print(sentence_block) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
